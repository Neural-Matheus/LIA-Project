# ADR.003 — Pipeline de embeddings + FAISS para RAG jurídico (Súmulas do STJ) — v2 (per-number + 2-estágios opcional)

## Context and Problem Statement

Com o corpus chunkado (ADR.002 v2), precisamos de um retriever que:

- gere embeddings consistentes (mesmo modelo em index e query);
- faça busca densa em FAISS;
- ranqueie súmulas (não apenas chunks), já que a unidade de resposta é "qual Súmula é".

## Decision Drivers

- **Qualidade:** bom Recall@k para identificar a súmula correta.
- **Simplicidade e reprodutibilidade** no início (arquivos, sem infra pesada).
- **Evolução clara** para HNSW/IVF ou vetor DB quando escalar.

## Considered Options

1. FAISS IndexFlatIP + L2 normalize nos chunks, com fusão por número ✅
2. FAISS HNSW (aproximado) para baixa latência em N grande
3. FAISS IVF-PQ/OPQ para milhões de vetores (memória)
4. DB vetorial (Qdrant/Milvus) já na v1

## Decision Outcome

**v1:** IndexFlatIP (cosseno via normalização L2) + docstore JSON.
**Ranqueamento por súmula (per-number):** agregação de scores dos top-M chunks por number.
**Opcional 2-estágios:** índice number-level (centróides por súmula) → shortlist; depois explorar chunks só dessas súmulas.

### Por quê

- FlatIP é simples e exato, ótimo até centenas de milhares de chunks.
- Per-number reduz competição "interna" entre chunks da mesma súmula, melhorando a decisão de qual súmula.
- 2-estágios acelera e estabiliza ranking de números com custo baixo.

## Pipeline (Design)

### Artefatos

**Corpus (canônico):** sumulas_chunks.jsonl

**Índice de chunks:**
- chunks.faiss (IndexFlatIP)
- docstore.json (ids, texts, numbers, sections)
- X.npy (cache de embeddings, opcional)
- manifest.json (modelo, dim, created_at, fonte)

**Índice por número (opcional):**
- numbers.faiss (centróides mean/max por súmula)
- numbers_meta.json (numbers, groups de chunks)

### Embeddings

- **Modelo ST:** paraphrase-multilingual-mpnet-base-v2 (default qualidade) ou MiniLM (velocidade).
- **max_seq_length:** 384 (MiniLM: 400–416), normalize L2 (cosine-ready).
- **Batch:** 64 (GPU leve), 16–32 (CPU).
- **FP32;** na GPU pode usar FP16 no forward, normalizando depois.

### Indexação (chunks)

- faiss.IndexFlatIP(dim); faiss.normalize_L2(X); index.add(X).
- Persistir FAISS + docstore + manifest (+ X.npy).

### Recuperação (consulta → números)

1. Encode query (normalize_embeddings=True).
2. Buscar top-M chunks (ex.: M=100–200).
3. **Fusão por número (per-number):**
   - **sum_sqrt (default):** soma dos scores por número dividida por sqrt(n_chunks) (desbalanceia menos).
   - **Alternativas:** max, sum, RRF (bom quando mistura BM25 + denso).
4. **Pesos por seção (leve viés):** enunciado(+10%), referencias(+5%), header(-10%), etc.
5. Rank final de números; selecionar evidências (enunciado + 1–2 excertos) conforme budget.

### 2-Estágios (opcional)

- **Stage-1 (numbers.faiss):** consulta retorna top-N súmulas via centróides (mean/max).
- **Stage-2 (chunks.faiss):** restringe busca de chunks a essas N súmulas e aplica a mesma fusão per-number.

### Self-match

Se a query vier de um chunk do próprio corpus (avaliação), ignorar o mesmo id para não inflar R@1.

## Defaults (v1)

- **Encoder:** MPNet; max_seq_length=384; L2 normalize.
- **FAISS:** IndexFlatIP.
- **Top-M chunks:** 150 (ajustável).
- **Pooling per-number:** sum_sqrt (default) com pesos por seção leves.
- **2-estágios:** desabilitado por padrão; habilitar quando o N crescer ou quiser latência menor.

## Observabilidade

- Tempo de encode (corpus/queries).
- Tempo de busca FAISS (Stage-1/2).
- Recall@k per-number em dev set.
- Distribuição de scores e margem (top1–top2) para calibrar thresholds de decisão (aceitar/abster).

## Consequências

- Pronto pra uso no RAG: retorna qual súmula e evidências (chunks).
- Fácil de evoluir: plugar reranker cross-encoder nos candidatos top-N; somar BM25 e fazer RRF; migrar para HNSW/IVF quando escalar.

## Risks & Mitigações

- **Flat pode ficar lento >300k–500k chunks** ⇒ HNSW ou IVF-PQ depois.
- **Embeddings multilíngues zero-shot em jurídico PT podem errar nuances** ⇒ fine-tuning leve (pairs enunciado↔excerto + hard negatives) numa ADR futura.
- **Agregação mal calibrada (over/under-weight seções)** ⇒ ajustar pesos e M (top-chunks) com validação.