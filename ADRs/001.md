# ADR.001 — Estratégia de extração do PDF e geração do dataset (parsing, limpeza e consolidação)

## Context and Problem Statement

A fonte primária atual é um **PDF** das Súmulas do STJ. Precisamos extrair **todos os registros** com campos definidos, lidando com *noise* de PDF (quebras, cabeçalhos/rodapés, acentuação, labels coladas) e garantindo **confiabilidade** do enunciado e metadados.

## Decision Drivers

* **Robustez** a ruídos e variações de layout do PDF
* **Determinismo** e reprodutibilidade do pipeline
* **Qualidade** do parsing (não perder enunciado; segmentar corretamente por súmula)
* **Manutenibilidade** (código simples, extensível)
* **Velocidade razoável** (sem depender de serviços externos)

## Considered Options

1. **PyPDF2 simples + regex** em cima do texto bruto.
2. **pdfminer/PyPDF2 + heurísticas de segmentação em duas passadas** (precisa + ingênua) e **consolidação por "score de qualidade"**.
3. **Scraping/ingest do site SCON** (HTML) ao invés de PDF.
4. **Extração assistida por LLM** (IE fraca) com *post-processing*.

## Pros and Cons

### 1) PyPDF2 + regex simples
**+** Rápido de implementar  
**–** Frágil a layouts variados; propenso a "colar labels"/quebras ruins

### 2) pdfminer/PyPDF2 + heurísticas + consolidação (duas passadas)
**+** **Mais robusto**:
* limpeza de headers/footers recorrentes
* segmentação "precisa" (*start em "Súmula N" → até a próxima "Súmula" após o primeiro "Enunciado:"*)
* fallback "ingênuo" (split amplo por "Súmula N")
* **consolidação**: escolher o melhor bloco por `quality_score` (conta campos não vazios)  
**+** Previne capturar entradas de índice/sumário como se fossem súmulas  
**–** Um pouco mais de código, porém ainda simples/manutenível

### 3) Scraping SCON (HTML)
**+** Texto geralmente mais limpo do que PDF  
**–** Requer crawler/estabilidade do site; pode mudar layout/endpoint; fora do escopo imediato

### 4) LLM para extração
**+** Flexível para variações de layout  
**–** Custo, latência e necessidade de *guardrails*; risco de alucinação; desnecessário por ora

## Decision Outcome

**Escolha:** **Opção 2** — pipeline determinístico com **pdfminer/PyPDF2**, **duas segmentações** (precisa+ingênua) e **consolidação por qualidade**.

## Resumo do pipeline (implementado)

1. **Extração de texto**: tenta **PyPDF2**; se output curto ou falha, cai para **pdfminer.six**.
2. **Pré-limpeza**: normaliza quebras, remove cabeçalhos/rodapés, colapsa linhas em branco.
3. **Segmentação "precisa"**: do cabeçalho `Súmula {N}` até a **próxima** `Súmula` **após** o primeiro `Enunciado:` (evita capturar índices).
4. **Segmentação "ingênua"**: split por `^Súmula \d+$`, como fallback.
5. **Parsing de campos**: captura flexível de labels (`Enunciado:`, `Referências Legislativas:`, `Órgão Julgador:`, `Data da decisão:`, `Fonte:`, `Excerto…`) aceitando **mesma linha** ou **linha seguinte**; variantes sem acento.
6. **Consolidação**: mescla candidatos por número e mantém **o de maior **`quality_score`.
7. `canonical_text`: concatena campos relevantes (ver ADR.001).
8. **Saídas**: `sumulas_stj.json` e `sumulas_stj.csv` (UTF-8).

## Critérios básicos de QA (automáticos)

* Cada registro tem `id == number` e `enunciado` não vazio (quando disponível no PDF).
* `canonical_text` gerado (≥ 1 linha além do cabeçalho).
* Amostragem manual (spot-check) de entradas conhecidas (ex.: **Súmula 60**).

## Consequences

### Positivas
* **Dataset confiável e reproduzível** a partir do PDF atual.
* **Pronto para indexação** (FAISS) e para iterações futuras (chunking, scraping SCON).
* Código **limpo e extensível**; fácil ajustar labels/heurísticas.

### Riscos/Mitigação
* **Variações futuras** de layout no PDF → ajustar regex/heurísticas (baixo custo).
* **Campos colados** em alguns pontos → já tratamos com *trim/guards*; monitorar casos extremos.
* **Contagem diferente** entre versões do PDF → pipeline é determinístico; versionar artefatos.
