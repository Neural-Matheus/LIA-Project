# ADR.004 — Encoder de sentenças para o RAG jurídico (troca para SBERT multilíngue)

## Context and Problem Statement

Os primeiros testes usavam BERT PT "puro" (token CLS/mean pooling ad-hoc). O comportamento em similaridade semântica variava e exigia mais tuning. Precisamos de um sentence encoder já otimizado para semântica e pooling adequado, com bom desempenho em PT-BR jurídico e latência aceitável.

## Decision Drivers

- Qualidade semântica em PT-BR (recall@k alto, queries curtas)
- Robustez sem fine-tuning inicial (zero-shot)
- Desempenho/latência e footprint razoáveis
- Compatibilidade direta com FAISS e pipeline atual

## Considered Options

- BERTimbau + pooling manual
- mBERT/XLM-R + pooling manual
- **Sentence-Transformers "paraphrase-multilingual-mpnet-base-v2"** ✅
- Sentence-Transformers "paraphrase-multilingual-MiniLM-L12-v2"

## Decision Outcome

**Escolha v1:** sentence-transformers/paraphrase-multilingual-mpnet-base-v2  
**Fallback:** paraphrase-multilingual-MiniLM-L12-v2 para GPU/CPU fracas.

**Motivos:** SBERT já vem com pooling e objetivo de treinamento voltados a similaridade; cobertura multilíngue funciona bem em PT; MPNet entrega melhor qualidade; MiniLM é mais leve para throughput.

## Consequences

- Ganho de recall@k nas tarefas de "achar a súmula pelo trecho"
- Implementação simples (encode normalizado L2 → FAISS IP)
- Teto de qualidade melhor que BERT "puro" sem fine-tuning

## Risks & Mitigations

- **Risco:** Domínio jurídico PT pode exigir ajuste fino  
  **Mitigação:** planejar fine-tuning leve (pairs enunciado↔excerto) em ADR futura
- **Risco:** Dependência do modelo (1.1GB no MPNet)  
  **Mitigação:** cache local, MiniLM como fallback
